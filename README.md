# LLM Scratch Scratch

## Intro

This is a scratchpad project that implements different LLM parts from scratch, also builds and trains small model variants of popular LLM architectures.

## Contents

### [LLM algo components](./llm_algo_components/)
- Attention
  - [scaled dot-product attention](./llm_algo_components/attention/scaled_dot_product_attention/)
  - [multi-head attention](./llm_algo_components/attention/MHA/)

### Models From Scratch

### Training / Fine-tuning 

### Optimization / Distributed


## Acknowledgments

- [Sebastian Raschka](https://sebastianraschka.com/) 's amazing book [Build a Large Language Model From Scratch](https://www.manning.com/books/build-a-large-language-model-from-scratch)

## History

- 2025/06/26 Project start
- 2025/06/27 
  - Add [scaled dot-product attention](./llm_algo_components/attention/scaled_dot_product_attention/)
  - Add [multi-head attention](./llm_algo_components/attention/MHA/)
